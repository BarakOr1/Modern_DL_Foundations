{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyM7R5+uCCFmN2Gu+caHOsyK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["This notebook demonstrates how to build, train, and evaluate two simple Multi-Layer Perceptron (MLP) models for classifying handwritten digits from the MNIST dataset. The task is to compare the performance of a model with no dropout against a model with a dropout rate of 0.2, specifically looking at how dropout affects overfitting."],"metadata":{"id":"wNmbtMH-7aGT"}},{"cell_type":"markdown","metadata":{"id":"03dced63"},"source":["Load the MNIST dataset from Keras and preprocess the images for the MLP model. This involves normalizing the pixel values and flattening the images into vectors."]},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import layers, models\n","\n","# Define brand colors for graphs\n","logo_black = \"#000000\"\n","logo_blue = \"#1b45eb\""],"metadata":{"id":"Hz_QoBj_rzkA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This cell loads the MNIST dataset, which consists of handwritten digits. It then preprocesses the data by normalizing the pixel values of the images to be between 0 and 1 and flattens the 28x28 images into 784-element vectors. The data is split into training and testing sets."],"metadata":{"id":"XW58Z0_-podm"}},{"cell_type":"code","source":["# Load the MNIST dataset from Keras (handwritten digits: 0–9)\n","# x_train and x_test are images (28x28), y_train and y_test are their labels\n","(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n","\n","# Normalize the images: pixel values from [0, 255] → [0, 1]\n","x_train = x_train.astype(\"float32\") / 255.0\n","x_test  = x_test.astype(\"float32\") / 255.0\n","\n","# Flatten the 28x28 images into 784-element vectors\n","x_train = x_train.reshape(-1, 28 * 28)\n","x_test  = x_test.reshape(-1, 28 * 28)"],"metadata":{"id":"7wpRJnCur3-c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1. Complete the missing parts in the code below:\n","\n","* Define the input shape for the images (hint: 28×28 = 784).\n","\n","* Choose the correct activation function for each layer from the list:\n","ELU / ReLU / GeLU / Sigmoid / Softmax\n","\n","* Defien the optimizer as 'adam'"],"metadata":{"id":"JkJGXnupqOj-"}},{"cell_type":"code","source":["# ----------------------------------------------------\n","# FUNCTION TO BUILD A FULLY CONNECTED NEURAL NETWORK\n","# ----------------------------------------------------\n","def build_mlp(dropout_rate):\n","    \"\"\"\n","    Constructs a simple Multi-Layer Perceptron (MLP) with two hidden layers.\n","    dropout_rate: float between 0.0 and 1.0. The probability of dropping neurons during training.\n","    \"\"\"\n","    model = models.Sequential([\n","        layers.Input(shape=(???,)),                     # 784 = 28x28 pixels\n","        layers.Dense(256, activation='???'),           # First hidden layer with GELU activation\n","        layers.Dropout(dropout_rate),                   # Dropout layer to prevent overfitting\n","        layers.Dense(128, activation='???'),           # Second hidden layer\n","        layers.Dropout(dropout_rate),                   # Another dropout\n","        layers.Dense(10, activation='???')          # Output layer: 10 classes (digits 0-9)\n","    ])\n","\n","    # Compile the model with Adam optimizer and cross-entropy loss\n","    model.compile(\n","        optimizer='???',\n","        loss='sparse_categorical_crossentropy',\n","        metrics=['accuracy']\n","    )\n","    return model"],"metadata":{"id":"H0oPqy-Xt1_Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Train two models:\n","\n","* One with dropout_rate = 0.0 (no dropout).\n","\n","* One with dropout_rate = 0.2.\n","\n","* Save each model and its history."],"metadata":{"id":"lOpE_yP5rJQM"}},{"cell_type":"code","source":["# ----------------------------------------------------\n","# FUNCTION TO TRAIN A MODEL AND RETURN HISTORY\n","# ----------------------------------------------------\n","def train_model(dropout_rate, label):\n","    \"\"\"\n","    Trains the MLP model with a specific dropout rate.\n","    Returns the trained model and training history.\n","    \"\"\"\n","    print(f\"\\nTraining model with Dropout = {dropout_rate} ({label})\")\n","    model = build_mlp(dropout_rate)\n","    history = model.fit(\n","        x_train, y_train,\n","        validation_data=(x_test, y_test),\n","        epochs=50,\n","        batch_size=64,\n","        verbose=1   # Change to 0 if you don't want to see training output\n","    )\n","    return model, history\n","\n","# ----------------------------------------------------\n","# Train two models: one with Dropout 0, one with 0.2\n","# ----------------------------------------------------\n","model_0, hist_0 = train_model(???, \"Dropout 0\")\n","model_02, hist_02 = train_model(???, \"Dropout 0.2\")"],"metadata":{"id":"-LnwURdPt4TQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3. Compare their performance:\n","\n","* Plot the training and validation accuracy curves for both models on the same graph.\n","\n","* Observe how dropout influences overfitting."],"metadata":{"id":"lHH_qr8rrkQl"}},{"cell_type":"code","source":["epochs = range(1, 51)\n","\n","# Plot accuracy comparison in a separate figure\n","plt.figure(figsize=(7, 5)) # Adjusted figure size for a single plot\n","plt.plot(epochs, hist_0.history['accuracy'], label='Dropout 0 (Train)', color=logo_blue, linestyle=':')\n","plt.plot(epochs, hist_0.history['val_accuracy'], label='Dropout 0 (Validation)', color=logo_blue)\n","plt.plot(epochs, hist_02.history['accuracy'], label='Dropout 0.2 (Train)', color=logo_black, linestyle=':')\n","plt.plot(epochs, hist_02.history['val_accuracy'], label='Dropout 0.2 (Validation)', color=logo_black, linestyle='--')\n","plt.title(\"Accuracy per Epoch\")\n","plt.xlabel(f\"Epochs ({epochs[-1]} total)\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()\n","\n","# Plot loss comparison in a separate figure\n","plt.figure(figsize=(7, 5)) # Adjusted figure size for a single plot\n","plt.plot(epochs, hist_0.history['loss'], label='Dropout 0 (Train)', color=logo_blue, linestyle=':')\n","plt.plot(epochs, hist_0.history['val_loss'], label='Dropout 0 (Validation)', color=logo_blue)\n","plt.plot(epochs, hist_02.history['loss'], label='Dropout 0.2 (Train)', color=logo_black, linestyle=':')\n","plt.plot(epochs, hist_02.history['val_loss'], label='Dropout 0.2 (Validation)', color=logo_black, linestyle='--')\n","plt.title(\"Loss per Epoch\")\n","plt.xlabel(f\"Epochs ({epochs[-1]} total)\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.grid(True, linestyle='--', alpha=0.6)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"XxEWyXCnutbY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Visualizing predictions from the Dropout 0 and Dropout 0.2 models"],"metadata":{"id":"SF_3sAo0uepO"}},{"cell_type":"code","source":["# Get predictions for the test set\n","y_pred_probs_0 = model_0.predict(x_test)                     # Probabilities for each class for model_0\n","y_pred_0 = np.argmax(y_pred_probs_0, axis=1)                # Choose highest-probability class for model_0\n","\n","y_pred_probs_02 = model_02.predict(x_test)                   # Probabilities for each class for model_02\n","y_pred_02 = np.argmax(y_pred_probs_02, axis=1)              # Choose highest-probability class for model_02\n","\n","\n","# Select 25 random test images (using the same indices for both models)\n","indices = np.random.choice(len(x_test), 25, replace=False)\n","\n","# Plot the images with predicted and true labels for the Dropout 0 model\n","plt.figure(figsize=(10, 10))\n","plt.suptitle(\"Predictions from Dropout 0 Model\", fontsize=16)\n","for i, idx in enumerate(indices):\n","    img = x_test[idx].reshape(28, 28)\n","    true_label = y_test[idx]\n","    pred_label = y_pred_0[idx]\n","    plt.subplot(5, 5, i+1)\n","    plt.imshow(img, cmap=\"gray\")\n","    plt.title(f\"Pred: {pred_label}\\nTrue: {true_label}\", fontsize=9)\n","    plt.axis(\"off\")\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()\n","\n","# Plot the images with predicted and true labels for the Dropout 0.2 model\n","plt.figure(figsize=(10, 10))\n","plt.suptitle(\"Predictions from Dropout 0.2 Model\", fontsize=16)\n","for i, idx in enumerate(indices):\n","    img = x_test[idx].reshape(28, 28)\n","    true_label = y_test[idx]\n","    pred_label = y_pred_02[idx]\n","    plt.subplot(5, 5, i+1)\n","    plt.imshow(img, cmap=\"gray\")\n","    plt.title(f\"Pred: {pred_label}\\nTrue: {true_label}\", fontsize=9)\n","    plt.axis(\"off\")\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()"],"metadata":{"id":"FdnJt_h2upNf"},"execution_count":null,"outputs":[]}]}