{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyNkgMvhQG5iKM0wA/uXx9ht"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"96be079f"},"source":["# CIFAR10 Training with ResNet18 and Mixed Precision\n","\n","This notebook demonstrates how to train a ResNet18 model on the CIFAR10 dataset using PyTorch. It incorporates mixed precision training to potentially accelerate the training process and reduce memory consumption, especially when using a GPU.\n","\n","The notebook covers:\n","- Loading and preparing the CIFAR10 dataset.\n","- Initializing a ResNet18 model, optimizer, and loss function.\n","- Implementing a training loop with mixed precision using `torch.cuda.amp`.\n","- Monitoring the training progress and loss."]},{"cell_type":"code","source":["# ============================================================\n","# Mixed Precision vs Full Precision — CIFAR10 + ResNet18\n","# ============================================================\n","\n","import torch, time, gc\n","from torch import nn, optim\n","from torchvision.models import resnet18\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader\n","from torch.amp import autocast, GradScaler\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"Using device:\", device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDqQSPLbMQq3","executionInfo":{"status":"ok","timestamp":1760369456303,"user_tz":-180,"elapsed":9687,"user":{"displayName":"Barak Or","userId":"02488591995076339770"}},"outputId":"f269e81d-c8be-4e07-fac2-ded9ccf218e5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# ---------------------------\n","# Data\n","# ---------------------------\n","train_loader = DataLoader(\n","    CIFAR10(root='.', train=True, download=True, transform=ToTensor()),\n","    batch_size=128, shuffle=True\n",")\n","\n","# ---------------------------\n","# Helper function\n","# ---------------------------\n","def train_epoch(model, loader, optimizer, loss_fn, use_amp=False):\n","    model.train()\n","    total_loss = 0.0\n","    scaler = GradScaler('cuda') if use_amp else None\n","\n","    start = time.time()\n","    for x, y in loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","\n","        if use_amp:\n","            with autocast('cuda'):\n","                pred = model(x)\n","                loss = loss_fn(pred, y)\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","        else:\n","            pred = model(x)\n","            loss = loss_fn(pred, y)\n","            loss.backward()\n","            optimizer.step()\n","\n","        total_loss += loss.item()\n","\n","    elapsed = time.time() - start\n","    return total_loss / len(loader), elapsed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8SWCgH1XMS6y","executionInfo":{"status":"ok","timestamp":1760369477748,"user_tz":-180,"elapsed":21449,"user":{"displayName":"Barak Or","userId":"02488591995076339770"}},"outputId":"d119864b-bb72-4890-84f2-1fed61115445"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:17<00:00, 9.71MB/s]\n"]}]},{"cell_type":"code","source":["# ---------------------------\n","# Run FP32 baseline\n","# ---------------------------\n","model_fp32 = resnet18(num_classes=10).to(device)\n","opt_fp32 = optim.Adam(model_fp32.parameters(), lr=1e-3)\n","loss_fn = nn.CrossEntropyLoss()\n","\n","torch.cuda.reset_peak_memory_stats(device)\n","loss32, time32 = train_epoch(model_fp32, train_loader, opt_fp32, loss_fn, use_amp=False)\n","mem32 = torch.cuda.max_memory_allocated(device) / 1e6  # MB\n","\n","# ---------------------------\n","# Run AMP\n","# ---------------------------\n","gc.collect()\n","torch.cuda.empty_cache()\n","\n","model_amp = resnet18(num_classes=10).to(device)\n","opt_amp = optim.Adam(model_amp.parameters(), lr=1e-3)\n","\n","torch.cuda.reset_peak_memory_stats(device)\n","loss16, time16 = train_epoch(model_amp, train_loader, opt_amp, loss_fn, use_amp=True)\n","mem16 = torch.cuda.max_memory_allocated(device) / 1e6  # MB\n","\n","# ---------------------------\n","# Compare results\n","# ---------------------------\n","print(\"\\n=== Comparison Summary ===\")\n","print(f\"FP32  | Time: {time32:.2f}s | Peak Memory: {mem32:.1f} MB | Loss: {loss32:.3f}\")\n","print(f\"AMP   | Time: {time16:.2f}s | Peak Memory: {mem16:.1f} MB | Loss: {loss16:.3f}\")\n","\n","speedup = (time32 - time16) / time32 * 100\n","memsave = (mem32 - mem16) / mem32 * 100\n","print(f\"\\nSpeedup: {speedup:.1f}% faster with AMP\")\n","print(f\"Memory: {memsave:.1f}% less memory used\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pMXQ85_S0tkZ","executionInfo":{"status":"ok","timestamp":1760369501697,"user_tz":-180,"elapsed":23950,"user":{"displayName":"Barak Or","userId":"02488591995076339770"}},"outputId":"27204600-53e4-4b91-831c-d73e65e79a98"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Comparison Summary ===\n","FP32  | Time: 11.81s | Peak Memory: 270.5 MB | Loss: 1.368\n","AMP   | Time: 11.62s | Peak Memory: 431.4 MB | Loss: 1.380\n","\n","Speedup: 1.6% faster with AMP\n","Memory: -59.5% less memory used\n"]}]},{"cell_type":"code","source":["# ---------------------------\n","# Compare results\n","# ---------------------------\n","print(\"\\n=== Comparison Summary ===\")\n","print(f\"FP32  | Time: {time32:.2f}s | Peak Memory: {mem32:.1f} MB | Loss: {loss32:.3f}\")\n","print(f\"AMP   | Time: {time16:.2f}s | Peak Memory: {mem16:.1f} MB | Loss: {loss16:.3f}\")\n","\n","speedup = (time32 - time16) / time32 * 100\n","memsave = (mem32 - mem16) / mem32 * 100\n","print(f\"\\nSpeedup: {speedup:.1f}% faster with AMP\")\n","print(f\"Memory: {memsave:.1f}% less memory used\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeZOhNtp0uON","executionInfo":{"status":"ok","timestamp":1760369501733,"user_tz":-180,"elapsed":32,"user":{"displayName":"Barak Or","userId":"02488591995076339770"}},"outputId":"5251e1f7-41a9-4849-ec2e-c311dc5413d1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Comparison Summary ===\n","FP32  | Time: 11.81s | Peak Memory: 270.5 MB | Loss: 1.368\n","AMP   | Time: 11.62s | Peak Memory: 431.4 MB | Loss: 1.380\n","\n","Speedup: 1.6% faster with AMP\n","Memory: -59.5% less memory used\n"]}]}]}