{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"A100","authorship_tag":"ABX9TyM4IWX/ASyFE73/M1tr35qD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Understand and compare the three main approaches to Transfer Learning – Feature Extraction, Partial Fine-Tuning, and Full Fine-Tuning – using a pretrained ResNet model on Fashion MNIST."],"metadata":{"id":"2xDyb3ZnzoBI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"V9ImVGgZx7hw"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","from torch.utils.data import DataLoader\n","\n","transform = transforms.Compose([\n","    transforms.Grayscale(num_output_channels=3),\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.5]*3, [0.5]*3)\n","])\n","\n","train_data = datasets.FashionMNIST(root=\"./data\", train=True, download=True, transform=transform)\n","test_data  = datasets.FashionMNIST(root=\"./data\", train=False, download=True, transform=transform)\n","train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n","test_loader  = DataLoader(test_data, batch_size=64, shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","base_model = models.resnet18(weights=\"IMAGENET1K_V1\")"]},{"cell_type":"markdown","source":["Strategy 1: Feature Extraction (Fixed Base)"],"metadata":{"id":"CqPEIZINz95C"}},{"cell_type":"code","source":["# Freeze all layers\n","model = base_model\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","# Replace the final classification layer\n","model.fc = nn.Linear(512, 10)\n","model = model.to(device)\n","\n","# Train only the new classifier head\n","optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(2):  # few epochs for demonstration\n","    model.train()\n","    for x, y in train_loader:\n","        x, y = x.to(device), y.to(device)\n","        optimizer.zero_grad()\n","        loss = criterion(model(x), y)\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"id":"rtok_hDBzcWq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Strategy 2: Partial Fine-Tuning"],"metadata":{"id":"GQv--Ocgz6_O"}},{"cell_type":"code","source":["# Unfreeze only the last residual block (layer4) and the final classifier\n","model = base_model\n","for name, param in model.named_parameters():\n","    param.requires_grad = (\"layer4\" in name) or (\"fc\" in name)\n","\n","# Replace the classifier\n","model.fc = nn.Linear(512, 10)\n","model = model.to(device)\n","\n","# Train the unfrozen layers with a smaller learning rate\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"UvZgFAfjz1Ln"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Strategy 3: Full Fine-Tuning"],"metadata":{"id":"weDAZFKu0QMy"}},{"cell_type":"code","source":["# Unfreeze all layers\n","model = base_model\n","for param in model.parameters():\n","    param.requires_grad = True\n","\n","# Replace the classifier again\n","model.fc = nn.Linear(512, 10)\n","model = model.to(device)\n","\n","# Use a very small learning rate to avoid catastrophic forgetting\n","optimizer = optim.Adam(model.parameters(), lr=1e-6)\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"QVJJFi-G0Mdy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Evaluate Models"],"metadata":{"id":"zYvD2Uaa0S8g"}},{"cell_type":"code","source":["def evaluate(model):\n","    model.eval()\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x, y = x.to(device), y.to(device)\n","            pred = model(x).argmax(1)\n","            correct += (pred == y).sum().item()\n","            total += y.size(0)\n","    return correct / total\n","\n","# Compute accuracies after each stage (assuming separate models)\n","acc_fixed   = evaluate(model)   # Feature extraction\n","acc_partial = evaluate(model)   # Partial fine-tuning\n","acc_full    = evaluate(model)   # Full fine-tuning\n","\n","print(f\"Feature Extraction Accuracy: {acc_fixed:.3f}\")\n","print(f\"Partial Fine-Tuning Accuracy: {acc_partial:.3f}\")\n","print(f\"Full Fine-Tuning Accuracy: {acc_full:.3f}\")"],"metadata":{"id":"__HGMNgK0TTl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Which strategy achieved the highest accuracy, and why?\n","\n","In what situations would you prefer each approach (e.g., small dataset, limited compute, domain similarity)?\n","\n","Could you design a hybrid approach – starting with feature extraction and gradually unfreezing layers?"],"metadata":{"id":"Nxtr8lKV0aYt"}},{"cell_type":"code","source":[],"metadata":{"id":"kIu-K8QT0dSP"},"execution_count":null,"outputs":[]}]}